{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tech_review_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ac7aa3227474c50b23a9514ecb3b90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5caf2883b9c24aa0b3cfe2eff2d6a73e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f4c5efe8a1f42d99efad14985687140",
              "IPY_MODEL_ac1223e08670417b98a039f38fe7d6ea"
            ]
          }
        },
        "5caf2883b9c24aa0b3cfe2eff2d6a73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f4c5efe8a1f42d99efad14985687140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6d4722dc76b49f19698f639b3ef75b3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22b533106282429882341c99256709ae"
          }
        },
        "ac1223e08670417b98a039f38fe7d6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2784f7d89a6a48fcb81ed0c37a1d3b4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [02:20&lt;00:00, 35.06s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_322dd0ff5e16431e8be2d9059423d69e"
          }
        },
        "e6d4722dc76b49f19698f639b3ef75b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22b533106282429882341c99256709ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2784f7d89a6a48fcb81ed0c37a1d3b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "322dd0ff5e16431e8be2d9059423d69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bce61577a6124787981c78ddb87c956d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cb6afc510ab44fab21662d9c79d3f32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b29ad5f1b23b490b8cc5a6f620bf4a4f",
              "IPY_MODEL_ec68d8c686604906962d55a524fb495a"
            ]
          }
        },
        "3cb6afc510ab44fab21662d9c79d3f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b29ad5f1b23b490b8cc5a6f620bf4a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51dfeb68ed7e4582be0136fa5b2970c4",
            "_dom_classes": [],
            "description": "Epoch 0: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c88b10e9e2848d4894c0f1d478e6259"
          }
        },
        "ec68d8c686604906962d55a524fb495a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91413cc14ca1455e8c64814871191777",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [00:31&lt;00:00,  1.20it/s, training_loss=0.185]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_741aa070b8c24580a777a89ddfb547ae"
          }
        },
        "51dfeb68ed7e4582be0136fa5b2970c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c88b10e9e2848d4894c0f1d478e6259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91413cc14ca1455e8c64814871191777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "741aa070b8c24580a777a89ddfb547ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d11ae689ed5e47f096afec5b85d0d2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fb0156964854f13bf34cc90853906c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d3ca5bd2b844126ac0efea91bc048ff",
              "IPY_MODEL_f71b61a5da7045468f6497368758a228"
            ]
          }
        },
        "3fb0156964854f13bf34cc90853906c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d3ca5bd2b844126ac0efea91bc048ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25f456f0a43c4fd1bd5ef7209c5daab2",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40e8c2c00f6f4aebbe462e5b2a9bafa2"
          }
        },
        "f71b61a5da7045468f6497368758a228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81a9aa7d16f74120ab3f15053498f07c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [00:30&lt;00:00,  1.26it/s, training_loss=0.156]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d39ad77a784e41c5a4640f861aa61179"
          }
        },
        "25f456f0a43c4fd1bd5ef7209c5daab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40e8c2c00f6f4aebbe462e5b2a9bafa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81a9aa7d16f74120ab3f15053498f07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d39ad77a784e41c5a4640f861aa61179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e374d0689b44dc3974a1b22ecac46bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_977f3e12025b406dbfc54c65ec2af297",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31326d1ee7234986bf25bc4f53b53668",
              "IPY_MODEL_3396cdec624f4aa4bd19578251dc8d70"
            ]
          }
        },
        "977f3e12025b406dbfc54c65ec2af297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31326d1ee7234986bf25bc4f53b53668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f351233cb3d499288a9070201390782",
            "_dom_classes": [],
            "description": "Epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb4e0ecaaf4d4845a9ad8f4e4b6a7923"
          }
        },
        "3396cdec624f4aa4bd19578251dc8d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ffbc70c61384706b1cf8b5be6b13e7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [00:30&lt;00:00,  1.25it/s, training_loss=0.097]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53fe4c81aaef457f85f75ddf5a4bc1df"
          }
        },
        "7f351233cb3d499288a9070201390782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb4e0ecaaf4d4845a9ad8f4e4b6a7923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ffbc70c61384706b1cf8b5be6b13e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53fe4c81aaef457f85f75ddf5a4bc1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "556eca69fdd54ddf8243b407b10f8c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42a50ed5f0dd4ef2b16a5ca7e8f13400",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cf24ca312c84064867287c89cacd9f4",
              "IPY_MODEL_7ec29196c0dd4cc5888edd2fffbec6ed"
            ]
          }
        },
        "42a50ed5f0dd4ef2b16a5ca7e8f13400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cf24ca312c84064867287c89cacd9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c97b99b0c6fb4abbb01dfe83c67dfcce",
            "_dom_classes": [],
            "description": "Epoch 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b837ad7407374ea7818f1336776faeca"
          }
        },
        "7ec29196c0dd4cc5888edd2fffbec6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e089df57cec40418b39e8163b95e907",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [00:30&lt;00:00,  1.25it/s, training_loss=0.164]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e709977423f4eecac601d91b5daf2f2"
          }
        },
        "c97b99b0c6fb4abbb01dfe83c67dfcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b837ad7407374ea7818f1336776faeca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e089df57cec40418b39e8163b95e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e709977423f4eecac601d91b5daf2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zen030/tech_review/blob/master/tech_review_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "G9PJCJyf4rJG"
      },
      "source": [
        "# Sentiment Analysis using BERT\n",
        "###### zainalh2@illinois.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmDHZjz-4rJI"
      },
      "source": [
        "## 1. Introduction\n",
        "This document illustrates the use of the BERT pre-trained model to classify the sentiment of Twitter tweets.\n",
        "\n",
        "The target audience of the document:\n",
        "<ol>\n",
        "<li>The audience who has <i><b>no experience in BERT pre-training Model</b></i>.</li>\n",
        "<li>The audience who has the curiosity on how to use and fine-tune the BERT model for simple training tasks such as text classification (categorization).</li>\n",
        "<li>The audience who has some basic understanding of Data Mining and Machine Learning.</li>\n",
        "<ul>\n",
        "<li> Understand the concept of Text Mining.</li>\n",
        "<li> Understand the concept of Training and Validation datasets</li>\n",
        "<li> Understand the concept of F1-Score evaluation</li>\n",
        "</ul>\n",
        "<li>The audience who have basic knowledge of Python 3, PyTorch usage, and Jupyter Notebook.</li>\n",
        "<li>And of course, the audience who is looking forward to spending fun time with Python code!</li>\n",
        "</ol>\n",
        "\n",
        "The main sources of inpiration of this document are the following Internet sources:\n",
        "<ol>\n",
        "<li>Cousera course: https://www.coursera.org/learn/sentiment-analysis-bert/home/welcome</li>\n",
        "<li>An article: https://mccormickml.com/2019/07/22/BERT-fine-tuning/</li>\n",
        "</ol>\n",
        "\n",
        "I try to combine BERT implementation and concept from both sources into a single document. I hope this document will be useful for everyone who is new to BERT world!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SECaiI8E4rJJ"
      },
      "source": [
        "## 2. What is BERT and Text Sentiment Analysis?\n",
        "### 2. 1. What is BERT?\n",
        "BERT is <i><b>Bidirectional Encoded Representations from Transformer</b></i> is a Natural Processing Language (NLP) pre-training model developed by Google (https://en.wikipedia.org/wiki/BERT_(language_model)). \n",
        "\n",
        "This means BERT provides a \"base\" model that is already trained using large number of text corpus. Luckily Google folks had already did this for us, and they shared the model to the world for us to use for free! Hundreds of GPU hours needed to train the original base BERT model.\n",
        "\n",
        "Useful Internet sources to understand BERT:\n",
        "1.\tBERT for dummies: https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
        "2.\tThe Illustrated BERT: http://jalammar.github.io/illustrated-bert/\n",
        "3.\tThe BERT original paper:  https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "### 2. 2. What is Text Sentiment analysis?\n",
        "\n",
        "Text Sentiment Analysis is a study in Text Mining to systematically identify, extract, quantify and study subjective information in un-structured text data (https://en.wikipedia.org/wiki/Sentiment_analysis).\n",
        "\n",
        "Imagine we have a “smart” module in which we can feed text data as an input. The “smart” module, implemented as a software code, will be able to output the sentiment found in the text data, as illustrated by the diagram below:\n",
        "\n",
        "![Sentiment_Analysis_Illustration.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwTiQGT0e1x2"
      },
      "source": [
        "In the illustration above, we pass a text data <b>“I don’t like the apple. It’s rotten!”</b>. We as human can easily identify that the opinion holder expressed his/her negative sentiment about an apple. To us the reason is so obvious that the apple is rotten. But for a computer to understand the sentiment, it requires complex computation model.  We can use BERT to model the computation of the “smart” module to detect sentiment found in text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jff-Dvs4rJL"
      },
      "source": [
        "# 3. Case study\n",
        "This document uses a case study implemented in Software code section to illustrate BERT capability to classify the sentiment found in text data.\n",
        "\n",
        "The dataset is labelled Twitter tweet. Each label expresses the sentiment of the tweet. In software code, we will split the dataset into training and validation datasets. Training dataset will be used to train base BERT model. Using the trained BERT model, we will use validation dataset to evaluate the accuracy of the trained BERT model.\n",
        "\n",
        "## 3.1. Dataset\n",
        "Case study uses dataset which we can freely download from the Internet. \n",
        "### 3.1.1. Dataset Source\n",
        "Dataset is taken from the source:\n",
        "<ol><li>\n",
        "Wang, Bo; Tsakalidis, Adam; Liakata, Maria; Zubiaga, Arkaitz; Procter, Rob; Jensen, Eric (2016): SMILE Twitter Emotion dataset. figshare. Dataset. https://doi.org/10.6084/m9.figshare.3187909.v2\n",
        "</li></ol>\n",
        "\n",
        "### 3.1.2. Text structure in the dataset\n",
        "Before we use and analyze the dataset using BERT, I will describe the data format found in the dataset as follow:\n",
        "\n",
        "<ol>\n",
        "<li>\n",
        "Dataset has 3085 lines (tweets). Each record consists of 3 columns.\n",
        "<ul>\n",
        "<li>Column-1: The unique ID of the line/tweet</li>\n",
        "<li>Column-2: The tweet message</li>\n",
        "<li>Column-3: The sentiment label of the message (sad, happy, etc.)</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li>\n",
        "Sample data from the dataset:\n",
        "611537640857411584,\"@britishmuseum @SenderosP The Rosetta Stone ;)\",happy\n",
        "<ul>\n",
        "<li>Column-1: 611537640857411584</li>\n",
        "<li>Column-2: \"@britishmuseum @SenderosP The Rosetta Stone ;)\"</li>\n",
        "<li>Column-3: happy</li>\n",
        "</ul>\n",
        "</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhgwzvFW4rJM"
      },
      "source": [
        "## 3.2. Software Code\n",
        "This Jupyter Notebook is also stored in Github: https://github.com/zen030/tech_review/blob/master/tech_review_colab.ipynb\n",
        "\n",
        "Detail explanation of each step in the software code section is decribed in the comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVhQWLAUWquB"
      },
      "source": [
        "### 3.2.1. Using Google Colab\n",
        "\n",
        "The software code is implemented and tested using Google Colab environment.\n",
        "\n",
        "Introduction about this environment can be found here: https://colab.research.google.com/notebooks/intro.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NSDS82c40cu",
        "outputId": "134339e3-afca-4755-aa3e-94451d4e8dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check if the GPU is available in the Colab environment\n",
        "# To activate GPU, in this Colab Notebook, go to Edit -> Notebook Settings\n",
        "# And make sure GPU is selected as Hardware Accelerator\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MlORkwH4_UC",
        "outputId": "c961c530-5f2c-446d-db82-c5bb6dbde0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Since we are going to use PyTorch and GPU\n",
        "# We need to tell PyTorch to use GPU explicitly (By default CPU will be used)\n",
        "import torch\n",
        "\n",
        "# If GPU is available.\n",
        "if torch.cuda.is_available():    \n",
        "    # PyTorch to use the GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If GPU is not available. Use the CPU.\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqXVtTPR4rJN"
      },
      "source": [
        "### 3.2.2. Analyze the dataset using pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "2WaFDsLy4rJc"
      },
      "source": [
        "# Load data from file to pandas DataFrame\n",
        "import pandas as pd  # https://pandas.pydata.org/\n",
        "# dataframe columns: [id, text, category]. Column id is the index.\n",
        "df = pd.read_csv('sample_data/smile-annotations-final.csv', names=['id', 'text', 'category'])\n",
        "df.set_index('id', inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "on_t2eD94rJg",
        "outputId": "10c77126-8ad3-4d48-ef62-d5e35ffb59a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Take a look at first 5 records\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611857364396965889</th>\n",
              "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
              "      <td>nocode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text category\n",
              "id                                                                            \n",
              "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "GueVjtqo4rJk",
        "outputId": "21a4f773-3a16-4671-d42a-1ff087777cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Number of record of each category\n",
        "df.category.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nocode               1572\n",
              "happy                1137\n",
              "not-relevant          214\n",
              "angry                  57\n",
              "surprise               35\n",
              "sad                    32\n",
              "happy|surprise         11\n",
              "happy|sad               9\n",
              "disgust|angry           7\n",
              "disgust                 6\n",
              "sad|disgust             2\n",
              "sad|angry               2\n",
              "sad|disgust|angry       1\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "M4QqNclj4rJn"
      },
      "source": [
        "# Filter out multiple label (the ones with | character) to the sake of simplicty.\n",
        "df = df[~df.category.str.contains('\\|')]\n",
        "# Filter out 'nocode' category. 'nocode' does not represent particular sentiment.\n",
        "df = df[df.category != 'nocode']\n",
        "# Filter out 'disgust' since it has only 6 records. We need more record to train the model.\n",
        "df = df[df.category != 'disgust']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "BVGLnXaY4rJq",
        "outputId": "3b8874b1-334c-4ff4-97e7-cf8b216b3f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Record counting of each category after data filter\n",
        "df.category.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "BQqdKP4N4rJu"
      },
      "source": [
        "# Assign label to each category. Label value is integer.\n",
        "# Label will be used by the model to classify the text sentiment. \n",
        "possible_labels = df.category.unique()\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "df['label'] = df.category.replace(label_dict)    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "06VNAb934rJx",
        "outputId": "e3ad0b16-6297-40ca-d208-6e7770646a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Review the first 5 records after the new label column added.\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611570404268883969</th>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  ... label\n",
              "id                                                                     ...      \n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...  ...     0\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...  ...     0\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...  ...     0\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...  ...     0\n",
              "611570404268883969  @NationalGallery @ThePoldarkian I have always ...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "6K7uSmrG4rJ0"
      },
      "source": [
        "### 3.2.2. Split the dataset into training dataset and validation dataset\n",
        "Dataset is split with the following distribution:\n",
        "- 85% as Training dataset: This is used to train the model.\n",
        "- 15% as Validation dataset: This is used to evaluate the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "aXV1yKj_4rJ0"
      },
      "source": [
        "# We will use sklearn library to split the dataset into training and validation dataset\n",
        "from sklearn.model_selection import train_test_split # https://scikit-learn.org/"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "RxQvXfmg4rJ4"
      },
      "source": [
        "# Here we split the dataset. The 80% vs 20% data split is considered a fair split.\n",
        "# However we definitely need to have a bigger data size for training compared to testing dataset.\n",
        "# Thus the split for our case:\n",
        "#   1) 80% as training dataset\n",
        "#   2) 20% as validation dataset\n",
        "# To choose which one goes to traning or validation dataset, it will be done randomly.\n",
        "# traing_test_split function will use random_state to randomly choose the dataset.\n",
        "# random_state set to 42. Popular integer random seeds are 0 and 42.\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                  df.label.values, \n",
        "                                                  test_size=0.20, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "KARwPFvK4rJ6",
        "outputId": "a08b90c2-3e2b-460f-83bf-15128f9851d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Adding a new column called \"data_type\".\n",
        "# this is to label each text record either it is \"train\"-ing dataset\n",
        "# or \"val\"-idation dataset \n",
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "# print dataframe to see the first 5 records\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611570404268883969</th>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  ... data_type\n",
              "id                                                                     ...          \n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...  ...     train\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...  ...       val\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...  ...     train\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...  ...     train\n",
              "611570404268883969  @NationalGallery @ThePoldarkian I have always ...  ...     train\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "YYGbY0jU4rJ9",
        "outputId": "3a9cc002-8a38-42be-a408-df77d787975a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Verify the data distribution by category and data_type.\n",
        "# Here we should have 80% vs 20% distribution for each category & data_type.\n",
        "df.groupby(['category', 'label', 'data_type']).count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>train</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>train</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>train</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text\n",
              "category     label data_type      \n",
              "angry        2     train        45\n",
              "                   val          12\n",
              "happy        0     train       910\n",
              "                   val         227\n",
              "not-relevant 1     train       171\n",
              "                   val          43\n",
              "sad          3     train        26\n",
              "                   val           6\n",
              "surprise     4     train        28\n",
              "                   val           7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "EunFvt054rKA"
      },
      "source": [
        "### 3.2.2. Tokenizing and Encoding\n",
        "Tokenization in BERT is another interesting topic to explore. BERT uses WordPiece tokenization strategy. \n",
        "\n",
        "Internet sources to explore this topic further:\n",
        "- Original paper: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf\n",
        "- An article about BERT Token Embedding: https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bFo02G_d4z",
        "outputId": "4c0b3001-72c6-4619-83e1-c45be57635b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We will use Huggingface library to instatiate transformers.\n",
        "# Reference about Huggingface transformers: https://github.com/huggingface/transformers\n",
        "# By default Google Colab does NOT have transformers installed.\n",
        "# The command below will install transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "EkO4MKgc4rKB"
      },
      "source": [
        "from transformers import BertTokenizer # https://huggingface.co/transformers/model_doc/bert.html\n",
        "from torch.utils.data import TensorDataset # https://pytorch.org/\n",
        "import torch"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "x7S6lfzk4rKE"
      },
      "source": [
        "# we create our BERT tokenizer.\n",
        "# this will create WordPiece tokenizer which is required by BERT model.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfjSB0ZCVMYB",
        "outputId": "adc693a9-03e6-4885-9b47-68086efaf377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Before we move on to the next, we should have one check done.\n",
        "# This check will help us decide on how to encode our text data (details below).\n",
        "df.text.str.len().max()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "MGIKai664rKH"
      },
      "source": [
        "# This part is all about preparing our data!\n",
        "# We encode our data into a format that BERT model can understand.\n",
        "# It will add special tokens to the text data: [CLS] and [SEP]\n",
        "# It will add special [PAD] token after [SEP] in each text record.\n",
        "# Why? Because BERT accepts fixed-length data with maximum 512 token.\n",
        "# In our case, max_length is set to 152 considering maximum length of our text data is 149\n",
        "# return_tensors='pt' means we are preparing our encoded data for PyTorch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].text.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    max_length = 152,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].text.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True,     \n",
        "    max_length = 152,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "# BERT id representation for each token \n",
        "# input_ids_*\n",
        "\n",
        "# Attention mask to differiantiate between token data and padding [PAD] token\n",
        "# mask = 1 for token data\n",
        "# mask = 0 for padding [PAD] token\n",
        "# attention_masks_*\n",
        "\n",
        "# create tensor for the category label\n",
        "# labels_*\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "6UXGhain4rKJ",
        "outputId": "3d3cfd06-e1f5-4055-cab4-c35bb5335d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's take a look at our text data in a BERT encoded representation!\n",
        "# This is how BERT model \"see\" our text data.\n",
        "encoded_data_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 16092,  3897,  ...,     0,     0,     0],\n",
              "        [  101,  1030, 10682,  ...,     0,     0,     0],\n",
              "        [  101,  1030,  2329,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1523,  1030,  ...,     0,     0,     0],\n",
              "        [  101,  1030,  3680,  ...,     0,     0,     0],\n",
              "        [  101,  1030,  2120,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU_uKR7U4rKN"
      },
      "source": [
        "# Create the Tensor dataset. We will pass this tensor datasets to data loader.\n",
        "# For more details about data loader, carry on to the next sections.\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "MmuSFCCS4rKV"
      },
      "source": [
        "### 3.2.2. Setting Pre-Trained BERT Model\n",
        "\n",
        "The original BERT paper presented two model sizes:\n",
        "- BERT BASE: 12 Encoder Layers\n",
        "- BERT LARGE: 24 Encoder Layers\n",
        "This case study uses base-uncased model (uncased means all the character in the text data are treated as lower case characters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "FpYX6G354rKV"
      },
      "source": [
        "# For complete list of BERT Model available in huggingface: https://huggingface.co/models\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "lO9CfcBU4rKY",
        "outputId": "c7f67bba-bd9d-42ab-9c05-6da78c0ca110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Here, we will use a pre-tained BERT model BertForSequenceClassification\n",
        "# BertForSequenceClassification is basically BERT Base model with different top layers\n",
        "# and output types designed to accomodate specific NLP task such as classification task.\n",
        "# More detail about BertForSequenceClassification: https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "# device in current case is set to GPU\n",
        "model.to(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "V1l0C61L4rKa"
      },
      "source": [
        "### 3.2.2. Creating Data Loaders\n",
        "Data loader is responsible to pass a batch of data (TensorDataset) to the model to process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "QVKSW7NY4rKb"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "4xbOMQku4rKe"
      },
      "source": [
        "# Number of text records pass to the model at the same batch\n",
        "# batch_size=32 is recommended in the BERT original paper\n",
        "batch_size = 32 \n",
        "\n",
        "# Create data loader for training TensorDataset\n",
        "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
        "# Create data loader for validation TensorDataset\n",
        "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "gcPiCe9D4rKh"
      },
      "source": [
        "### 3.2.2. Setting Up Optimiser and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "H-9tIFnk4rKi"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "9vLRFiG84rKk"
      },
      "source": [
        "# Optimizer in a nutshell is the algorithm to speedup the model learning process (training cost reduction at higher speed).\n",
        "# For more detail about optimizer: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "# For the purposes of fine-tuning, it is recommend choosing from the following values:\n",
        "#   1. Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "#   2. The epsilon parameter eps = 1e-8 is a very small number to prevent any division by zero in the implementation.\n",
        "# This is the recommendation from BERT original paper.\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  eps=1e-8)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_fMLVOmt4rKp"
      },
      "source": [
        "# Recommended to have 2, 3 or 4 EPOCHS for fine-tuning BERT on a specific NLP task.\n",
        "# This is the recommendation from BERT original paper.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# Create the learning rate scheduler. Reference: https://huggingface.co/transformers/main_classes/optimizer_schedules.html\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "GfE-E0dx4rKt"
      },
      "source": [
        "### 3.2.2. Defining Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "9uD0ytRR4rKu"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Function to calculate F1 score: https://en.wikipedia.org/wiki/F-score\n",
        "# F1 score is harmonic mean of the precision and recall\n",
        "def calculate_f1_score(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "# Function to calculate accuracy per category.\n",
        "def accuracy_per_category(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "oAN-7z_74rK6"
      },
      "source": [
        "### 3.2.2. Creating our Training Loop\n",
        "\n",
        "This training code is based on the `run_glue.py` script here: https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDW0b9cKs4c_"
      },
      "source": [
        "# Helper function to evaluate the validation result from the trained model\n",
        "def evaluate(dataloader_val):\n",
        "    # To set the model into a training mode\n",
        "    model.eval()\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():     \n",
        "            # evaluate the validation dataset   \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "yNQ3JwzE4rLG",
        "outputId": "3d086274-b0ca-412d-b5e3-65cfbbb3e057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "3ac7aa3227474c50b23a9514ecb3b90b",
            "5caf2883b9c24aa0b3cfe2eff2d6a73e",
            "9f4c5efe8a1f42d99efad14985687140",
            "ac1223e08670417b98a039f38fe7d6ea",
            "e6d4722dc76b49f19698f639b3ef75b3",
            "22b533106282429882341c99256709ae",
            "2784f7d89a6a48fcb81ed0c37a1d3b4b",
            "322dd0ff5e16431e8be2d9059423d69e",
            "bce61577a6124787981c78ddb87c956d",
            "3cb6afc510ab44fab21662d9c79d3f32",
            "b29ad5f1b23b490b8cc5a6f620bf4a4f",
            "ec68d8c686604906962d55a524fb495a",
            "51dfeb68ed7e4582be0136fa5b2970c4",
            "4c88b10e9e2848d4894c0f1d478e6259",
            "91413cc14ca1455e8c64814871191777",
            "741aa070b8c24580a777a89ddfb547ae",
            "d11ae689ed5e47f096afec5b85d0d2ac",
            "3fb0156964854f13bf34cc90853906c5",
            "5d3ca5bd2b844126ac0efea91bc048ff",
            "f71b61a5da7045468f6497368758a228",
            "25f456f0a43c4fd1bd5ef7209c5daab2",
            "40e8c2c00f6f4aebbe462e5b2a9bafa2",
            "81a9aa7d16f74120ab3f15053498f07c",
            "d39ad77a784e41c5a4640f861aa61179",
            "5e374d0689b44dc3974a1b22ecac46bf",
            "977f3e12025b406dbfc54c65ec2af297",
            "31326d1ee7234986bf25bc4f53b53668",
            "3396cdec624f4aa4bd19578251dc8d70",
            "7f351233cb3d499288a9070201390782",
            "cb4e0ecaaf4d4845a9ad8f4e4b6a7923",
            "7ffbc70c61384706b1cf8b5be6b13e7d",
            "53fe4c81aaef457f85f75ddf5a4bc1df",
            "556eca69fdd54ddf8243b407b10f8c49",
            "42a50ed5f0dd4ef2b16a5ca7e8f13400",
            "5cf24ca312c84064867287c89cacd9f4",
            "7ec29196c0dd4cc5888edd2fffbec6ed",
            "c97b99b0c6fb4abbb01dfe83c67dfcce",
            "b837ad7407374ea7818f1336776faeca",
            "0e089df57cec40418b39e8163b95e907",
            "1e709977423f4eecac601d91b5daf2f2"
          ]
        }
      },
      "source": [
        "from tqdm.notebook import tqdm # https://github.com/tqdm/tqdm\n",
        "import random\n",
        "\n",
        "# The random seed used to initialise the weights \n",
        "# and select the order of the training data.\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# loop over the full dataset for a number of epochs times\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    \n",
        "    # To set the model into a training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Measure the total training loss for each epoch\n",
        "    loss_train_total = 0\n",
        "    # Progressbar to show the progress of the current epoch\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    \n",
        "    # Process each batch in the current epoch\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass. \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Unpack current training batch.\n",
        "        # batch contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        # This is the actual learning\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        # Current training loss\n",
        "        loss = outputs[0]\n",
        "        # Current total training loss\n",
        "        loss_train_total = loss_train_total + loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        \n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "    # Save the trained BERT model for the current epoch iteration    \n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = calculate_f1_score(predictions, true_vals)\n",
        "\n",
        "    # Report the summary of epoch iteration\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ac7aa3227474c50b23a9514ecb3b90b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bce61577a6124787981c78ddb87c956d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 0', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 0\n",
            "Training loss: 0.9385107320708197\n",
            "Validation loss: 0.6466381788253784\n",
            "F1 Score (Weighted): 0.7314488234202776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d11ae689ed5e47f096afec5b85d0d2ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 1\n",
            "Training loss: 0.6040981573027533\n",
            "Validation loss: 0.4958310484886169\n",
            "F1 Score (Weighted): 0.7769332452081957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e374d0689b44dc3974a1b22ecac46bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 2\n",
            "Training loss: 0.4714568764776797\n",
            "Validation loss: 0.4410941883921623\n",
            "F1 Score (Weighted): 0.7949400259557755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "556eca69fdd54ddf8243b407b10f8c49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 3\n",
            "Training loss: 0.38135904718089747\n",
            "Validation loss: 0.43996200487017634\n",
            "F1 Score (Weighted): 0.8077848630778315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM1o1e39nXA1"
      },
      "source": [
        "### 3.2.2. Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "FRB_Oxlx4rLM",
        "outputId": "bd7456c8-e581-4ff6-fe88-55905655194e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate all the trained BERT model (for each EPOCH)\n",
        "for _, epoch in enumerate(range(epochs)):\n",
        "  tqdm.write(f'EPOCH: {epoch}')\n",
        "  model.load_state_dict(torch.load('finetuned_BERT_epoch_{0}.model'.format(epoch), map_location=torch.device('cpu')))\n",
        "  _, predictions, true_vals = evaluate(dataloader_validation)\n",
        "  accuracy_per_category(predictions, true_vals)\n",
        "  tqdm.write(f'########################################################################')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n",
            "Class: happy\n",
            "Accuracy: 227/227\n",
            "\n",
            "Class: not-relevant\n",
            "Accuracy: 9/43\n",
            "\n",
            "Class: angry\n",
            "Accuracy: 0/12\n",
            "\n",
            "Class: sad\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: surprise\n",
            "Accuracy: 0/7\n",
            "\n",
            "########################################################################\n",
            "EPOCH: 1\n",
            "Class: happy\n",
            "Accuracy: 217/227\n",
            "\n",
            "Class: not-relevant\n",
            "Accuracy: 23/43\n",
            "\n",
            "Class: angry\n",
            "Accuracy: 0/12\n",
            "\n",
            "Class: sad\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: surprise\n",
            "Accuracy: 0/7\n",
            "\n",
            "########################################################################\n",
            "EPOCH: 2\n",
            "Class: happy\n",
            "Accuracy: 219/227\n",
            "\n",
            "Class: not-relevant\n",
            "Accuracy: 26/43\n",
            "\n",
            "Class: angry\n",
            "Accuracy: 0/12\n",
            "\n",
            "Class: sad\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: surprise\n",
            "Accuracy: 0/7\n",
            "\n",
            "########################################################################\n",
            "EPOCH: 3\n",
            "Class: happy\n",
            "Accuracy: 221/227\n",
            "\n",
            "Class: not-relevant\n",
            "Accuracy: 28/43\n",
            "\n",
            "Class: angry\n",
            "Accuracy: 0/12\n",
            "\n",
            "Class: sad\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: surprise\n",
            "Accuracy: 0/7\n",
            "\n",
            "########################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4KakzYd4rLU"
      },
      "source": [
        "# 4. Summary\n",
        "\n",
        "This case study demonstrates that we can use a pre-trained BERT model to quickly create a model with minimal effort and training time using the pytorch interface.\n",
        "\n",
        "Let us consider the accuracy result of EPOCH # 3:\n",
        "- happy: 221/227\n",
        "- not-relevant: 28/43\n",
        "- angry: 0/12\n",
        "- sad: 0/6\n",
        "- surprise: 0/7\n",
        "\n",
        "'happy' category has the best result. The model can clasify the 221 sentiment out of 227 tweets.\n",
        "\n",
        "'not-relevant' has less accuracy but it improves over the EPOCH iterations.\n",
        "The trained model doesn't give good result/accuracy for the 'angry', \n",
        "\n",
        "'sad', and 'suprise' categories. The fact the training and validation dataset for these categories is a lot less than the other categories might be the major factor.\n",
        "\n",
        "This we can see that BERT can be trained and performed better with a larger corpus."
      ]
    }
  ]
}